{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df57d971",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8510c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d667027",
   "metadata": {},
   "source": [
    "# Feature extraction from audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2baab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                       | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████████                                                                                                    | 1/10 [00:13<01:58, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 1\n",
      "Processing folder 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████████████▏                                                                                        | 2/10 [00:25<01:42, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 2\n",
      "Processing folder 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████████████████▎                                                                             | 3/10 [00:38<01:30, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 3\n",
      "Processing folder 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████████████████▍                                                                  | 4/10 [00:53<01:22, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 4\n",
      "Processing folder 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████▌                                                       | 5/10 [01:07<01:08, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 5\n",
      "Processing folder 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████████████████████▌                                            | 6/10 [01:18<00:51, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 6\n",
      "Processing folder 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████████████████████████▋                                 | 7/10 [01:30<00:37, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 7\n",
      "Processing folder 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████▊                      | 8/10 [01:42<00:24, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 8\n",
      "Processing folder 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████▉           | 9/10 [01:54<00:12, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 9\n",
      "Processing folder 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:07<00:00, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 10\n",
      "Number of folders processed: 10\n",
      "Shape of the first folder's feature array: (873, 13, 173)\n",
      "Number of classes in each folder: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_folders = 10\n",
    "all_audios_features_array = []\n",
    "class_IDs = []\n",
    "base_folder_path = r\"C:\\Users\\icham\\OneDrive\\Desktop\\dataset\\urbansoundclasification\\UrbanSound8K\\UrbanSound8K\\audio\"\n",
    "n_frames = 100  # Choose a fixed number of frames\n",
    "\n",
    "for i in tqdm(range(1, num_folders + 1)):\n",
    "    audio_folder_path = base_folder_path + \"\\\\fold\" + str(i)\n",
    "    audio_files = [f for f in os.listdir(audio_folder_path) if os.path.isfile(os.path.join(audio_folder_path, f))]\n",
    "    folder_audio_feature_arr = []  # Separate array for each folder\n",
    "    class_id = []\n",
    "\n",
    "    print(f\"Processing folder {i}...\")\n",
    "\n",
    "    for filename in audio_files:\n",
    "        file_path = os.path.join(audio_folder_path, filename)\n",
    "        y, sr = librosa.load(file_path)\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # Pad or truncate along the time axis (columns)\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, max(0, n_frames - mfccs.shape[1]))), mode='constant')\n",
    "\n",
    "        folder_audio_feature_arr.append(mfccs)\n",
    "        class_id.append(int(filename.split('-')[1]))  # Assuming the class ID is encoded in the file name\n",
    "\n",
    "    # Pad or truncate along the time axis (columns) for all files in the folder\n",
    "    max_frames = max(arr.shape[1] for arr in folder_audio_feature_arr)\n",
    "    folder_audio_feature_arr = np.array([np.pad(arr, ((0, 0), (0, max_frames - arr.shape[1])), mode='constant') for arr in folder_audio_feature_arr])\n",
    "\n",
    "    class_id = np.array(class_id)\n",
    "    class_IDs.append(class_id)\n",
    "    \n",
    "    all_audios_features_array.append(folder_audio_feature_arr)\n",
    "    print(f\"Finished processing folder {i}\")\n",
    "\n",
    "# Convert the outer list to a list of NumPy arrays\n",
    "all_audios_features_array = np.array(all_audios_features_array, dtype=object)\n",
    "\n",
    "# Print information about the generated arrays\n",
    "print(\"Number of folders processed:\", len(all_audios_features_array))\n",
    "print(\"Shape of the first folder's feature array:\", all_audios_features_array[0].shape)\n",
    "print(\"Number of classes in each folder:\", [len(np.unique(class_ids)) for class_ids in class_IDs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d830d",
   "metadata": {},
   "source": [
    "# one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc708b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "class_IDs_one_hot = []\n",
    "for folder in class_IDs:\n",
    "    one_hot_encoded = to_categorical(folder,num_classes = 10)\n",
    "    class_IDs_one_hot.append(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38192139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42ed95",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db1d9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(filters=32, kernel_size=5, padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(strides=(2, 2), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=5, padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(strides=(2, 2), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(strides=(2, 2), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(units=2048, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(units=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5fde0",
   "metadata": {},
   "source": [
    "# compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a03531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb4df46",
   "metadata": {},
   "source": [
    "#  Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c706b44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 873 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "873/873 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 2/10\n",
      "873/873 [==============================] - 3s 3ms/sample - loss: 1.5427 - acc: 0.8999 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 3/10\n",
      "873/873 [==============================] - 2s 3ms/sample - loss: 1.5408 - acc: 0.9001 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 4/10\n",
      "873/873 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Train on 888 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "888/888 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 2/10\n",
      "888/888 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 3/10\n",
      "888/888 [==============================] - 3s 3ms/sample - loss: 1.5445 - acc: 0.8998 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "888/888 [==============================] - 3s 3ms/sample - loss: 1.5461 - acc: 0.8995 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 5/10\n",
      "888/888 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 6/10\n",
      "888/888 [==============================] - 2s 3ms/sample - loss: 1.5427 - acc: 0.8999 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 7/10\n",
      "888/888 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Train on 925 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 2/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5406 - val_acc: 0.9001\n",
      "Epoch 5/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5406 - val_acc: 0.9001\n",
      "Epoch 6/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5426 - acc: 0.8999 - val_loss: 1.5390 - val_acc: 0.9001\n",
      "Epoch 7/10\n",
      "925/925 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5406 - val_acc: 0.9001\n",
      "Epoch 8/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5406 - val_acc: 0.9001\n",
      "Epoch 9/10\n",
      "925/925 [==============================] - 3s 3ms/sample - loss: 1.5408 - acc: 0.9001 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Train on 990 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "990/990 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "990/990 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5443 - val_acc: 0.8999\n",
      "Epoch 3/10\n",
      "990/990 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 4/10\n",
      "990/990 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 5/10\n",
      "990/990 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Epoch 6/10\n",
      "990/990 [==============================] - 3s 3ms/sample - loss: 1.5426 - acc: 0.9000 - val_loss: 1.5407 - val_acc: 0.9001\n",
      "Train on 936 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "936/936 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5408 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "936/936 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "936/936 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "936/936 [==============================] - 3s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Train on 823 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "823/823 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "823/823 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "823/823 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5443 - val_acc: 0.8999\n",
      "Epoch 4/10\n",
      "823/823 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5443 - val_acc: 0.8999\n",
      "Train on 838 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5408 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5443 - acc: 0.8999 - val_loss: 1.5427 - val_acc: 0.8999\n",
      "Epoch 3/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5410 - acc: 0.9000 - val_loss: 1.5443 - val_acc: 0.8999\n",
      "Epoch 4/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5427 - acc: 0.8998 - val_loss: 1.5414 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5380 - acc: 0.8998 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5443 - acc: 0.8999 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "838/838 [==============================] - 2s 3ms/sample - loss: 1.5370 - acc: 0.9004 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Train on 806 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "806/806 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "806/806 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5445 - val_acc: 0.8998\n",
      "Epoch 3/10\n",
      "806/806 [==============================] - 2s 3ms/sample - loss: 1.5428 - acc: 0.8999 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "806/806 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5447 - val_acc: 0.8998\n",
      "Train on 816 samples, validate on 837 samples\n",
      "Epoch 1/10\n",
      "816/816 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "816/816 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "816/816 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5425 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "816/816 [==============================] - 2s 3ms/sample - loss: 1.5425 - acc: 0.9000 - val_loss: 1.5443 - val_acc: 0.8999\n",
      "Epoch 5/10\n",
      "816/816 [==============================] - 2s 3ms/sample - loss: 1.5427 - acc: 0.8999 - val_loss: 1.5443 - val_acc: 0.8999\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def cnn(x_train, y_train, x_test, y_test):\n",
    "    for i in range(len(x_train)): \n",
    "        original_shape_train = x_train[i].shape\n",
    "        original_shape_test = x_test[0].shape\n",
    "        x_train_data = np.reshape(x_train[i], (*original_shape_train, 1))\n",
    "        y_train_data = y_train[i]\n",
    "        x_test_data = np.reshape(x_test[0], (*original_shape_test, 1))\n",
    "        y_test_data = y_test[0]\n",
    "        \n",
    "        # Define the EarlyStopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)  # Stop if validation loss does not improve for 3 epochs\n",
    "        \n",
    "        # Fit the model with EarlyStopping callback\n",
    "        model.fit(x_train_data, y_train_data, epochs=10, batch_size=30, \n",
    "                  validation_data=(x_test_data, y_test_data), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b177b",
   "metadata": {},
   "source": [
    "# Creating train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee55b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in each iteration a new folder is assigned to testing and others are used for training\n",
    "\n",
    "for i in range(num_folders):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for j in range(num_folders):\n",
    "           if (i == j):\n",
    "                x_test.append(all_audios_features_array[i])\n",
    "                y_test.append(class_IDs_one_hot[i])\n",
    "           if  (i!=j):\n",
    "             x_train.append(all_audios_features_array[j])\n",
    "             y_train.append(class_IDs_one_hot[j])   \n",
    "    cnn(x_train,y_train,x_test,y_test)         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2cf91",
   "metadata": {},
   "source": [
    "# Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32ddb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the test data.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model.\n",
    "        x_test: List of test features.\n",
    "        y_test: List of true labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "        float: Test loss.\n",
    "        float: Test accuracy.\n",
    "    \"\"\"\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        # Reshape the test data if necessary\n",
    "        x_test_data = np.reshape(x_test[i], (*x_test[i].shape, 1))\n",
    "        \n",
    "        # Evaluate the model on the test data\n",
    "        test_loss, test_accuracy = model.evaluate(x_test_data, y_test[i], verbose=0)\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    avg_test_accuracy = np.mean(test_accuracies)\n",
    "    \n",
    "    return avg_test_loss, avg_test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "967b67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5442957902324954\n",
      "Test Accuracy: 0.89988035\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
